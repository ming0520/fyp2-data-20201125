{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differences of json and simplejson library\n",
    "#https://stackoverflow.com/questions/712791/what-are-the-differences-between-json-and-simplejson-python-modules\n",
    "import json #use to dump the json\n",
    "import simplejson as json #use to load the json\n",
    "import glob #use to load the file or directory\n",
    "\n",
    "import speech_recognition as sr #use to transcript purpose\n",
    "\n",
    "#for multirocess purpose\n",
    "#not use in this software, related multiprocess code in this project is commented\n",
    "import multiprocessing\n",
    "import threading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path for file\n",
    "audio_path = 'UclassAudioV1'\n",
    "script_path = 'TranscriptTxt'\n",
    "output_path = 'GentleAligned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load all the file\n",
    "files = glob.glob(f'{script_path}/*.txt')\n",
    "files_name = []\n",
    "for file in files:\n",
    "    print(file.split('\\\\')[1].split('.')[0])\n",
    "    files_name.append(file.split('\\\\')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gentle(file_name):\n",
    "    audio_path = 'UclassAudioV1'\n",
    "    script_path = 'TranscriptTxt'\n",
    "    output_path = 'GentleAligned'\n",
    "    input_audio = f'./{audio_path}/{file_name}.wav'\n",
    "    input_script = f'./{script_path}/{file_name}.txt'\n",
    "    output_json = f'./{output_path}/{file_name}.json'\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.check_output(f'curl -F \"audio=@{input_audio}\" -F \"transcript=@{input_script}\" \"http://localhost:8765/transcriptions?async=false\"')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "    outjson = json.loads(result)\n",
    "    with open(f'{output_json}', 'w') as f:\n",
    "        json.dump(outjson, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display all the file name\n",
    "for file_name in files_name:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Align all audio file with the word and store in json format\n",
    "#output directory is GentleAligned\n",
    "for file_name in files_name:\n",
    "    print('Processing'+file_name)\n",
    "    process_gentle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Prototype for gentle processing (word allignment)\n",
    "\n",
    "# #ffmpeg -i my_video.mp4 -c copy -map 0:a output_audio.mp4\n",
    "# #https://opensource.com/article/17/6/ffmpeg-convert-media-file-formats\n",
    "\n",
    "# file_name = 'F_0101_10y4m_1'\n",
    "# input_audio = f'./{audio_path}/{file_name}.wav'\n",
    "# input_script = f'./{script_path}/{file_name}.txt'\n",
    "# output_file = f'./{output_path}/{file_name}.json'\n",
    "# # input_audio = f'converted.wav'\n",
    "\n",
    "# #check audio file info\n",
    "# #ffprobe -i yourFile.mp4 -show_streams -select_streams a:0\n",
    "# # Convert audio file command\n",
    "# #ffmpeg -y -i \"M_0394_09y2m_1.wav\" -acodec pcm_s16le -ac 1 -ar 16000 -af lowpass=3000,highpass=200 \"converted.wav\"\n",
    "# #gentle audio allignment process\n",
    "# try:\n",
    "#     result = subprocess.check_output(f'curl -F \"audio=@{input_audio}\" -F \"transcript=@{input_script}\" \"http://localhost:8765/transcriptions?async=false\"')\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "    \n",
    "# #Next Cell\n",
    "# outjson = json.loads(result)\n",
    "# #Next Cell\n",
    "# with open(f'{output_json}', 'w') as f:\n",
    "#     json.dump(outjson, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Multithreading\n",
    "# pool = multiprocessing.Pool()\n",
    "# inputs = files_name\n",
    "# outputs_async = pool.map_async(process_gentle, inputs) \n",
    "# outputs = outputs_async.get() \n",
    "# print(\"Output: {}\".format(outputs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Multiprocessing\n",
    "# jobs = []\n",
    "# for file_name in files_name:\n",
    "#     t1 = threading.Thread(target=process_gentle, args=(file_name,))\n",
    "#     jobs.append(t1)\n",
    "#     t1.start()\n",
    "#     print(p)\n",
    "\n",
    "# for job in jobs:\n",
    "#     job.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Multiprocessing\n",
    "# if __name__ == '__main__':\n",
    "#     jobs = []\n",
    "#     for file_name in files_name:\n",
    "#         p = multiprocessing.Process(target=process_gentle, args=(file_name,))\n",
    "#         jobs.append(p)\n",
    "#         p.start()\n",
    "#         print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Transcription purpose\n",
    "# def speech_recognition():\n",
    "#     #google speech recognition\n",
    "#     # Suggested format for google speech regonition\n",
    "#     #http://christophebuffet.com/blog/using-google-speech-api-transcribe-interviews/\n",
    "#     # Reference for how to use google speech recognition\n",
    "#     #https://pypi.org/project/SpeechRecognition/2.1.3/\n",
    "#     #https://realpython.com/python-speech-recognition/\n",
    "#     #https://www.kdnuggets.com/2019/07/practical-speech-recognition-python-basics.html\n",
    "#     recognizer = sr.Recognizer()\n",
    "#     read_audio = sr.AudioFile(f'{input_audio}')\n",
    "#     with read_audio as source:\n",
    "#         audio = recognizer.record(source)\n",
    "#     # google_all = recognizer.recognize_google(audio,show_all=True)\n",
    "#     google_all = recognizer.recognize_google(audio)\n",
    "#     # print(google_all['alternative'][0]['transcript'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autoedit]",
   "language": "python",
   "name": "conda-env-autoedit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
